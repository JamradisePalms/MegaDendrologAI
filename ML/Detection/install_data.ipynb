{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b424bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting certifi (from roboflow)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting cycler (from roboflow)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from roboflow)\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting matplotlib (from roboflow)\n",
      "  Downloading matplotlib-3.10.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy>=1.18.5 (from roboflow)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting Pillow>=7.1.2 (from roboflow)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pi-heif<2 (from roboflow)\n",
      "  Downloading pi_heif-1.1.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting pillow-avif-plugin<2 (from roboflow)\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/pasheeee/MyProjects/MegaDendrologAI/.venv/lib/python3.13/site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting requests (from roboflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six in /Users/pasheeee/MyProjects/MegaDendrologAI/.venv/lib/python3.13/site-packages (from roboflow) (1.17.0)\n",
      "Collecting urllib3>=1.26.6 (from roboflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting tqdm>=4.41.0 (from roboflow)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting PyYAML>=5.3.1 (from roboflow)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->roboflow)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->roboflow)\n",
      "  Downloading fonttools-4.60.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (111 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pasheeee/MyProjects/MegaDendrologAI/.venv/lib/python3.13/site-packages (from matplotlib->roboflow) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->roboflow)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->roboflow)\n",
      "  Using cached charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl.metadata (36 kB)\n",
      "Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.0-cp313-cp313-macosx_14_0_arm64.whl (642 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m642.4/642.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp313-cp313-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading matplotlib-3.10.6-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\n",
      "Downloading fonttools-4.60.0-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl (205 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: pillow-avif-plugin, filetype, urllib3, tqdm, PyYAML, python-dotenv, pyparsing, Pillow, numpy, kiwisolver, idna, fonttools, cycler, charset_normalizer, certifi, requests, pi-heif, opencv-python-headless, contourpy, requests-toolbelt, matplotlib, roboflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [roboflow]/22\u001b[0m [roboflow]b]olbelt]less]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Pillow-11.3.0 PyYAML-6.0.2 certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 filetype-1.2.0 fonttools-4.60.0 idna-3.7 kiwisolver-1.4.9 matplotlib-3.10.6 numpy-2.3.3 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 pyparsing-3.2.5 python-dotenv-1.1.1 requests-2.32.5 requests-toolbelt-1.0.0 roboflow-1.2.9 tqdm-4.67.1 urllib3-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca94a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOFLOW_API_KEY = \"bqQx7aG8EwPnLZVzCCws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a22a70-8160-4ef7-b9d5-feb8c34aeccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jamradise/MegaDendrologAI/ML/Detection/data/tree')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fa39f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in /home/jamradise/MegaDendrologAI/ML/Detection/Data/trees-1 to yolov11:: 100%|██████████████████████████████████████████████████| 77864/77864 [00:03<00:00, 22166.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to /home/jamradise/MegaDendrologAI/ML/Detection/Data/trees-1 in yolov11:: 100%|██████████████████████████████████████████████████████| 1748/1748 [00:00<00:00, 8328.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "from pathlib import Path\n",
    "PATH_TO_SAVE_DATASET = Path(\"/home/jamradise/MegaDendrologAI/ML/Detection/Data\")\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "project = rf.workspace(\"tree-detection-v4x2j\").project(\"tree-quality-3\")\n",
    "version = project.version(7)\n",
    "dataset = version.download(\"yolov11\", location=str(PATH_TO_SAVE_DATASET / \"trees-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e741971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in /home/jamradise/MegaDendrologAI/ML/Detection/Data/shrubs-1 to yolov11:: 100%|█████████████████████████████████████████████████| 84690/84690 [00:03<00:00, 22313.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to /home/jamradise/MegaDendrologAI/ML/Detection/Data/shrubs-1 in yolov11:: 100%|█████████████████████████████████████████████████████| 1309/1309 [00:00<00:00, 6688.90it/s]\n"
     ]
    }
   ],
   "source": [
    "project = rf.workspace(\"govind-rai-aiwsm\").project(\"shrubs\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov11\", location=str(PATH_TO_SAVE_DATASET / \"shrubs-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15a6e356-ca2d-4f05-87ad-0d6eba2a9bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in /home/jamradise/MegaDendrologAI/ML/Detection/Data/shrubs-2 to yolov11:: 100%|██████████████████████████████████████████████████| 11008/11008 [00:01<00:00, 8421.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to /home/jamradise/MegaDendrologAI/ML/Detection/Data/shrubs-2 in yolov11:: 100%|███████████████████████████████████████████████████████| 494/494 [00:00<00:00, 9180.31it/s]\n"
     ]
    }
   ],
   "source": [
    "project = rf.workspace(\"mtlworkspace\").project(\"bush-detection\")\n",
    "version = project.version(7)\n",
    "dataset = version.download(\"yolov11\", location=str(PATH_TO_SAVE_DATASET / \"shrubs-2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "358364c3-8a6e-4166-96ed-2f360b385491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "project = rf.workspace(\"mohamed-snoqx\").project(\"tree-6szhy\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov11\", location=str(PATH_TO_SAVE_DATASET / \"trees-2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88d6a3-5689-4201-80eb-8360941b283b",
   "metadata": {},
   "source": [
    "# Concat all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c60d1a5-2f3b-4e07-ad0f-8bdf0943eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_paths = [str(PATH_TO_SAVE_DATASET / \"trees-1\"), str(PATH_TO_SAVE_DATASET / \"trees-2\")]\n",
    "shrubs = [str(PATH_TO_SAVE_DATASET / \"shrubs-1\"), str(PATH_TO_SAVE_DATASET / \"shrubs-2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e682c97-d980-4f50-aba4-a7458bf521db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/home/jamradise/MegaDendrologAI/ML/Detection/Data/trees-1',\n",
       "  '/home/jamradise/MegaDendrologAI/ML/Detection/Data/trees-2'],\n",
       " ['/home/jamradise/MegaDendrologAI/ML/Detection/Data/shrubs-1',\n",
       "  '/home/jamradise/MegaDendrologAI/ML/Detection/Data/shrubs-2'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_paths, shrubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce45ae19-3a86-40aa-9414-81eb46e496c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db35983d-8262-472f-aacc-a3ad60fbc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVE_DATASET = Path(\"/home/jamradise/MegaDendrologAI/ML/Detection/Data\")\n",
    "new_dataset_path = PATH_TO_SAVE_DATASET / \"combined_dataset\"\n",
    "new_dataset_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dab445b-0ef2-4591-8dd3-113bc79b9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    (new_dataset_path / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (new_dataset_path / split / \"labels\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37aebc89-fbac-47b5-af56-b2a428673189",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\"path\": PATH_TO_SAVE_DATASET / \"trees-1\", \"type\": \"tree\"},\n",
    "    {\"path\": PATH_TO_SAVE_DATASET / \"shrubs-1\", \"type\": \"shrub\"},\n",
    "    {\"path\": PATH_TO_SAVE_DATASET / \"shrubs-2\", \"type\": \"shrub\"},\n",
    "    {\"path\": PATH_TO_SAVE_DATASET / \"trees-2\", \"type\": \"tree\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5936aa8e-4c10-44a9-a8f0-97f98ac6134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    ds_path = ds[\"path\"]\n",
    "    ds_type = ds[\"type\"]\n",
    "    new_class_id = 0 if ds_type == \"tree\" else 1  # tree=0, shrub=1\n",
    "\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        src_images = ds_path / split / \"images\"\n",
    "        src_labels = ds_path / split / \"labels\"\n",
    "        \n",
    "        # Пропускаем, если папки не существуют\n",
    "        if not src_images.exists() or not src_labels.exists():\n",
    "            continue\n",
    "\n",
    "        # Обрабатываем каждый файл в split\n",
    "        for img_file in src_images.iterdir():\n",
    "            base_name = img_file.stem\n",
    "            ext = img_file.suffix\n",
    "            new_img_name = f\"{ds_path.name}_{base_name}{ext}\"\n",
    "            dest_img = new_dataset_path / split / \"images\" / new_img_name\n",
    "            \n",
    "            # Копируем изображение\n",
    "            shutil.copy(img_file, dest_img)\n",
    "            \n",
    "            # Обрабатываем аннотацию\n",
    "            label_file = src_labels / f\"{base_name}.txt\"\n",
    "            if label_file.exists():\n",
    "                with open(label_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                new_lines = []\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if not parts:  # пропускаем пустые строки\n",
    "                        continue\n",
    "                    # Заменяем class_id на новый\n",
    "                    parts[0] = str(new_class_id)\n",
    "                    new_lines.append(\" \".join(parts))\n",
    "                \n",
    "                new_label_name = f\"{ds_path.name}_{base_name}.txt\"\n",
    "                dest_label = new_dataset_path / split / \"labels\" / new_label_name\n",
    "                with open(dest_label, 'w') as f:\n",
    "                    f.write(\"\\n\".join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c6a4ba3-7d0d-488a-82cb-4ef8f2b368f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = {\n",
    "    \"path\": str(new_dataset_path),\n",
    "    \"train\": \"train/images\",\n",
    "    \"valid\": \"valid/images\",\n",
    "    \"test\": \"test/images\",\n",
    "    \"names\": {\n",
    "        0: \"tree\",\n",
    "        1: \"shrub\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7044545c-7368-4b46-b70e-20faf6fe28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_dataset_path / \"data.yaml\", 'w') as f:\n",
    "    yaml.dump(data_yaml, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bbc2e-ff7a-434f-af23-e5ea50221002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
