{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3357852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_encoders(pkl_path: str) -> dict:\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            label_encoders = pickle.load(f)\n",
    "        return label_encoders\n",
    "    except Exception as e:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabf02f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_label_encoders(r\"C:\\Users\\shari\\PycharmProjects\\MegaDendrologAI\\ML\\Classification\\results\\saved_models\\label_encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98ba70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import List, Dict\n",
    "import pickle\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.samples = []\n",
    "        self.label_encoders = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, labels_dict = self.samples[index]\n",
    "        image_encoded = Image.open(image_path).convert('RGB')\n",
    "        return image_encoded, labels_dict\n",
    "\n",
    "class ImageDatasetJson(BaseDataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        json_path: Path, \n",
    "        image_filepath_field: str, \n",
    "        target_fields: List[str],\n",
    "        label_encoders: Dict[str, LabelEncoder] = None\n",
    "    ):\n",
    "        self.json_path = json_path\n",
    "        self.image_filepath_field = image_filepath_field\n",
    "        self.target_fields = target_fields\n",
    "        self.samples = []\n",
    "        \n",
    "        with open(self.json_path, 'r', encoding='utf-8') as f:\n",
    "            images_dict = json.load(f)\n",
    "        \n",
    "        field_values = {field: [] for field in self.target_fields}\n",
    "        for image_classified in images_dict:\n",
    "            for field in self.target_fields:\n",
    "                field_values[field].append(image_classified[field])\n",
    "        \n",
    "        if label_encoders is None:\n",
    "            self.label_encoders = {}\n",
    "            for field in self.target_fields:\n",
    "                le = LabelEncoder()\n",
    "                le.fit(field_values[field])\n",
    "                self.label_encoders[field] = le\n",
    "        else:\n",
    "            self.label_encoders = label_encoders\n",
    "        \n",
    "        for image_classified in images_dict:\n",
    "            image_filepath = image_classified[self.image_filepath_field]\n",
    "            \n",
    "            labels_dict = {}\n",
    "            for field in self.target_fields:\n",
    "                value = image_classified[field]\n",
    "                encoded_value = self.label_encoders[field].transform([value])[0]\n",
    "                labels_dict[field] = encoded_value\n",
    "            \n",
    "            self.samples.append((image_filepath, labels_dict))\n",
    "    \n",
    "    def save_label_encoders(self, filepath: Path):\n",
    "        \"\"\"Сохраняет LabelEncoder'ы в виде простого JSON с маппингами\"\"\"\n",
    "        \n",
    "        label_encoders_dict = {}\n",
    "        \n",
    "        for field_name, encoder in self.label_encoders.items():\n",
    "            label_encoders_dict[field_name] = {\n",
    "                str(cls): int(idx) for idx, cls in enumerate(encoder.classes_)\n",
    "            }\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(label_encoders_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "import torch\n",
    "from PIL import Image, ImageFile\n",
    "from typing import List, Tuple, Any, Callable, Dict\n",
    "\n",
    "\n",
    "class ImageCollator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        processor,\n",
    "        task_names: List[str]\n",
    "    ):\n",
    "        self.processor = processor\n",
    "        self.task_names = task_names\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels_dict = zip(*batch)\n",
    "        inputs = self.processor(images, return_tensors=\"pt\")\n",
    "        \n",
    "        labels = {}\n",
    "        for task_name in self.task_names:\n",
    "            task_labels = [label_dict[task_name] for label_dict in labels_dict]\n",
    "            labels[task_name] = torch.tensor(task_labels)\n",
    "        \n",
    "        inputs[\"labels\"] = labels\n",
    "        return inputs\n",
    "    \n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "\n",
    "class TrainConfigs:\n",
    "    class TreeClassificationModelWithMultiHeadMLP:\n",
    "        MODEL_NAME = 'microsoft/resnet-18'\n",
    "        TRAIN_JSON_FILEPATH = Path(r\"C:\\Users\\shari\\PycharmProjects\\MegaDendrologAI\\result.json\")\n",
    "        IMAGE_PROCESSOR = AutoImageProcessor.from_pretrained(\n",
    "            MODEL_NAME, use_fast=True\n",
    "        )\n",
    "        IMAGE_JSON_FIELD = \"image\"\n",
    "        TARGET_JSON_FIELD = {\n",
    "            \"tree_type\": 16, # number of unique trees based on the QWEN reports\n",
    "            \"has_hollow\": 2,\n",
    "            \"has_cracks\": 2,\n",
    "            # \"injuries\": 30, # number of unique injuries based on the QWEN reports\n",
    "            \"has_fruits_or_flowers\": 2,\n",
    "        }\n",
    "        PATH_TO_SAVE_MODEL = Path('ML/Classification/results/saved_models/hollow_classification_small.pth')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, List, Union, Optional\n",
    "\n",
    "class ResNetWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        resnet_model: str,\n",
    "        hidden_size: int = 256,\n",
    "        num_output_features: Union[int, Dict[str, int]] = 2,\n",
    "        num_hidden_layers: int = 1,\n",
    "        dropout: float = 0.1,\n",
    "        activation: str = \"relu\",\n",
    "        freeze_resnet: bool = False,\n",
    "    ):\n",
    "        super(ResNetWrapper, self).__init__()\n",
    "        \n",
    "        self.resnet = ResNetBackbone(model_name=resnet_model)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            dummy_output = self.resnet(dummy_input)\n",
    "            dummy_output = dummy_output.view(dummy_output.size(0), -1)\n",
    "            self.feature_size = dummy_output.shape[-1]\n",
    "        \n",
    "        if freeze_resnet:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.task_names = []\n",
    "        self.output_layers = nn.ModuleDict()\n",
    "        \n",
    "        if isinstance(num_output_features, int):\n",
    "            self.task_names = ['main']\n",
    "            self.output_layers['main'] = self._create_mlp(\n",
    "                input_size=self.feature_size,\n",
    "                hidden_size=hidden_size,\n",
    "                output_size=num_output_features,\n",
    "                num_hidden_layers=num_hidden_layers,\n",
    "                dropout=dropout,\n",
    "                activation=activation\n",
    "            )\n",
    "        else:\n",
    "            self.task_names = list(num_output_features.keys())\n",
    "            for task_name, num_classes in num_output_features.items():\n",
    "                self.output_layers[task_name] = self._create_mlp(\n",
    "                    input_size=self.feature_size,\n",
    "                    hidden_size=hidden_size,\n",
    "                    output_size=num_classes,\n",
    "                    num_hidden_layers=num_hidden_layers,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation\n",
    "                )\n",
    "    \n",
    "    def _create_mlp(\n",
    "        self, \n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_hidden_layers: int,\n",
    "        dropout: float,\n",
    "        activation: str\n",
    "    ) -> nn.Sequential:\n",
    "        layers = []\n",
    "        current_input_size = input_size\n",
    "        \n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.extend([\n",
    "                nn.Linear(current_input_size, hidden_size),\n",
    "                self._get_activation(activation),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            current_input_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(current_input_size, output_size))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> nn.Module:\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"leaky_relu\": nn.LeakyReLU(0.1),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"sigmoid\": nn.Sigmoid()\n",
    "        }\n",
    "        return activations.get(activation, nn.ReLU())\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        features = self.resnet(x)\n",
    "        if features.dim() == 4:  # [batch, channels, height, width]\n",
    "            features = features.view(features.size(0), -1)\n",
    "\n",
    "        if len(self.task_names) == 1:\n",
    "            return self.output_layers[self.task_names[0]](features)\n",
    "        else:\n",
    "            return {task_name: self.output_layers[task_name](features) \n",
    "                   for task_name in self.task_names}\n",
    "    \n",
    "    def unfreeze_resnet(self, unfreeze: bool = True):\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = unfreeze\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_CONFIG = TrainConfigs.TreeClassificationModelWithMultiHeadMLP\n",
    "\n",
    "\n",
    "task_names = list(CURRENT_CONFIG.TARGET_JSON_FIELD.keys())\n",
    "num_classes_per_task = CURRENT_CONFIG.TARGET_JSON_FIELD\n",
    "\n",
    "\n",
    "train_dataset = ImageDatasetJson(\n",
    "    CURRENT_CONFIG.TRAIN_JSON_FILEPATH,\n",
    "    CURRENT_CONFIG.IMAGE_JSON_FIELD,\n",
    "    target_fields=task_names\n",
    ")\n",
    "\n",
    "\n",
    "encoders_path = CURRENT_CONFIG.PATH_TO_SAVE_MODEL.parent / \"label_encoders.pkl\"\n",
    "train_dataset.save_label_encoders(encoders_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ffcab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shari\\PycharmProjects\\MegaDendrologAI\\.venv\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "le = load_label_encoders(r\"C:\\Users\\shari\\PycharmProjects\\MegaDendrologAI\\ML\\Classification\\results\\saved_models\\label_encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19aec99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_type': {0: 'Береза',\n",
       "  1: 'Вяз',\n",
       "  2: 'Дуб',\n",
       "  3: 'Ель',\n",
       "  4: 'Ива',\n",
       "  5: 'Каштан',\n",
       "  6: 'Клен остролистный',\n",
       "  7: 'Клен ясенелистный',\n",
       "  8: 'Липа',\n",
       "  9: 'Лиственница',\n",
       "  10: 'Осина',\n",
       "  11: 'Рябина',\n",
       "  12: 'Сосна',\n",
       "  13: 'Туя',\n",
       "  14: 'Ясень',\n",
       "  15: 'неопределено'},\n",
       " 'has_hollow': {0: '0', 1: '1'},\n",
       " 'has_cracks': {0: '0', 1: '1'},\n",
       " 'has_fruits_or_flowers': {0: '0', 1: '1'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_dict = {}\n",
    "for name, encoder in le.items():\n",
    "    le_dict[name] = {}\n",
    "    for key, value in enumerate(encoder.classes_):\n",
    "        le_dict[name][int(key)] = str(value)\n",
    "le_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510647a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
